{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Sandisk Memory Chip Reviews for Insights\n",
    "\n",
    "The following data came from the following source: http://jmcauley.ucsd.edu/data/amazon/. The top products are available in the **electronics_reviews_sorted_20kfirst.csv** file, and within it, the most popular product is the sandisk memory chip. The asin is the Amazon-specific product key for that product / product group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "electronics = pd.read_csv('electronics_reviews_sorted_20kfirst.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1336615</td>\n",
       "      <td>1336615</td>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>Purchased this for my device, it worked as adv...</td>\n",
       "      <td>10 25, 2013</td>\n",
       "      <td>A18K1ODH1I2MVB</td>\n",
       "      <td>0mie</td>\n",
       "      <td>MOAR SPACE!!!</td>\n",
       "      <td>1382659200</td>\n",
       "      <td>4914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1338394</td>\n",
       "      <td>1338394</td>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>I use this card to back up some of the files, ...</td>\n",
       "      <td>04 7, 2014</td>\n",
       "      <td>A23VI3E0M5KYES</td>\n",
       "      <td>George H.</td>\n",
       "      <td>SanDisk</td>\n",
       "      <td>1396828800</td>\n",
       "      <td>4914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1338378</td>\n",
       "      <td>1338378</td>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>I bought 3 when they were on sale but I did bu...</td>\n",
       "      <td>05 13, 2014</td>\n",
       "      <td>A302II84DZN7IU</td>\n",
       "      <td>Gee 35</td>\n",
       "      <td>go pro</td>\n",
       "      <td>1399939200</td>\n",
       "      <td>4914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338379</td>\n",
       "      <td>1338379</td>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>Works well for the Galaxy S3 and provides addi...</td>\n",
       "      <td>09 22, 2012</td>\n",
       "      <td>A2PIPECHFC8KPS</td>\n",
       "      <td>gellikit</td>\n",
       "      <td>Useful</td>\n",
       "      <td>1348272000</td>\n",
       "      <td>4914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1338380</td>\n",
       "      <td>1338380</td>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>Popped this into my Nvidia shield for extra st...</td>\n",
       "      <td>12 8, 2013</td>\n",
       "      <td>A2RULNH1LXYG1O</td>\n",
       "      <td>Gem Box \"tech junkie\"</td>\n",
       "      <td>Good SD Card for the Price</td>\n",
       "      <td>1386460800</td>\n",
       "      <td>4914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1        asin helpful  overall  \\\n",
       "0     1336615       1336615  B007WTAJTO  [0, 0]        5   \n",
       "1     1338394       1338394  B007WTAJTO  [0, 0]        5   \n",
       "2     1338378       1338378  B007WTAJTO  [0, 0]        5   \n",
       "3     1338379       1338379  B007WTAJTO  [1, 1]        5   \n",
       "4     1338380       1338380  B007WTAJTO  [0, 0]        5   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  Purchased this for my device, it worked as adv...  10 25, 2013   \n",
       "1  I use this card to back up some of the files, ...   04 7, 2014   \n",
       "2  I bought 3 when they were on sale but I did bu...  05 13, 2014   \n",
       "3  Works well for the Galaxy S3 and provides addi...  09 22, 2012   \n",
       "4  Popped this into my Nvidia shield for extra st...   12 8, 2013   \n",
       "\n",
       "       reviewerID           reviewerName                     summary  \\\n",
       "0  A18K1ODH1I2MVB                   0mie               MOAR SPACE!!!   \n",
       "1  A23VI3E0M5KYES              George H.                     SanDisk   \n",
       "2  A302II84DZN7IU                 Gee 35                      go pro   \n",
       "3  A2PIPECHFC8KPS               gellikit                      Useful   \n",
       "4  A2RULNH1LXYG1O  Gem Box \"tech junkie\"  Good SD Card for the Price   \n",
       "\n",
       "   unixReviewTime  counts  \n",
       "0      1382659200    4914  \n",
       "1      1396828800    4914  \n",
       "2      1399939200    4914  \n",
       "3      1348272000    4914  \n",
       "4      1386460800    4914  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electronics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B007WTAJTO'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sandisk_asin = electronics['asin'][0]\n",
    "sandisk_asin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sandisk = electronics[electronics['asin']==sandisk_asin]\n",
    "sandisk = sandisk[sandisk['reviewText'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "tokenizer = nltk.tokenize.TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_prepare(text):    \n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string pre-processed \n",
    "        1. converting to lower-case\n",
    "        2. replace special characters with a space\n",
    "        3. remove othe symbols\n",
    "        4. remove stopwords\n",
    "    \"\"\"\n",
    "    text = re.sub(REPLACE_BY_SPACE_RE, ' ', text)\n",
    "    text = re.sub(BAD_SYMBOLS_RE, '', text)\n",
    "    text = text.lower()\n",
    "    text = [word for word in tokenizer.tokenize(text) if word not in STOPWORDS]\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "def text_splitter(texts):\n",
    "    split_texts = [tokenizer.tokenize(text) for text in texts]\n",
    "    return split_texts\n",
    "def dict_counter(split_texts):\n",
    "    # split, then flatten the nested list of texts\n",
    "    flattened_list = [word for text in split_texts for word in text]\n",
    "    # init the dict\n",
    "    words_counts_dict = dict()\n",
    "    for word in flattened_list: \n",
    "        # if there is no key, get will return 0 (second argument default = 0), and then add 1 \n",
    "        # if there is a pre-existing key, it will add 1 to the pre-existing number\n",
    "        # the loop loops through every word occurence\n",
    "        words_counts_dict[word] = words_counts_dict.get(word, 0) + 1\n",
    "    return words_counts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prepared_texts = [text_prepare(text) for text in sandisk['reviewText']]\n",
    "split_texts = text_splitter(prepared_texts)\n",
    "words_counts = dict_counter(split_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Frequency of Words\n",
    "\n",
    "Plot the distribution of word frequencies. We see that most words (~80%) occur between 1-10 times. We'll exclude these from our vector representations of words to eliminate noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdYAAAEWCAYAAADb8rbuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab is 10740\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data = words_counts.values()\n",
    "\n",
    "# fixed bin size\n",
    "bins = np.arange(0, 100, 10) # fixed bin size\n",
    "\n",
    "plt.xlim([-20, 100])\n",
    "\n",
    "plt.hist(data, bins=bins, alpha=0.5)\n",
    "plt.title('Word Frequency Histogram (binsize = 10, for words appearing <101 times)')\n",
    "plt.xlabel('variable X (bin size = 5)')\n",
    "plt.ylabel('count')\n",
    "\n",
    "plt.show()\n",
    "print('Number of words in vocab is %s' % len(words_counts.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the above distribution, to eliminate noise, we will use only the top 2000 words in our model vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DICT_SIZE = 10740\n",
    "TOP_WORDS_LIST = sorted(words_counts, key = words_counts.__getitem__, reverse = True)[:DICT_SIZE]\n",
    "WORDS_TO_INDEX = {key: value for value, key in enumerate(TOP_WORDS_LIST)}\n",
    "INDEX_TO_WORDS = {key: value for key, value in enumerate(TOP_WORDS_LIST)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_bag_of_words(text, words_to_index, dict_size):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        dict_size: size of the dictionary\n",
    "        \n",
    "        return a vector which is a bag-of-words representation of 'text'\n",
    "    \"\"\"\n",
    "    text = tokenizer.tokenize(text)\n",
    "    ALL_WORDS = words_to_index.keys()\n",
    "    result_vector = np.zeros(dict_size)\n",
    "    for word in text: \n",
    "        if word in ALL_WORDS:\n",
    "            result_vector[words_to_index.get(word)] += 1\n",
    "    return result_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse as sp_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(prepared_texts, sandisk['overall'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create sparse vector representaitons of our bag of words representations of reviews\n",
    "\n",
    "X_train_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_train])\n",
    "X_test_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find out what words are associated with positive sentiment and negative sentiment \n",
    "\n",
    "In the following steps we'll investigate what drivers of our star score may be. In a sense, this may shed light on product features that consumers like and product features that are problematic. \n",
    "\n",
    "We will use correlation, because in multivariate regression, colinearity may cause misleading regression weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "correl = [(n,np.corrcoef(np.asarray(X_train_mybag[:,n].todense()).reshape(-1), y_train)[0,1]) for n in range(DICT_SIZE)]\n",
    "index, correlation = zip(*correl)\n",
    "\n",
    "correl_array = np.array(list(correlation))\n",
    "\n",
    "min_idx = np.argsort(correl_array)[:50]\n",
    "min_vals = correl_array[min_idx]\n",
    "\n",
    "max_idx = np.flip(np.argsort(correl_array)[-50:], axis = 0)\n",
    "max_vals = correl_array[max_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "months -0.2659524029693055\n",
      "return -0.2618115783695762\n",
      "tried -0.2514089720513546\n",
      "card -0.23886567721293225\n",
      "lost -0.21024947029578395\n",
      "back -0.20982958920377495\n",
      "died -0.20765789148262245\n",
      "replacement -0.20207856701460827\n",
      "even -0.19128292974093253\n",
      "failed -0.1906604449798398\n",
      "started -0.1904482996475814\n",
      "stopped -0.18795341204415106\n",
      "dead -0.18065460874817948\n",
      "bad -0.17721881299629677\n",
      "different -0.1697044981767688\n",
      "thought -0.16900127413810107\n",
      "defective -0.16807436675258988\n",
      "problem -0.16773159661390938\n",
      "removed -0.16511449475297227\n",
      "another -0.1633818117113342\n",
      "luck -0.16179933638001462\n",
      "would -0.16092744772691284\n",
      "format -0.157974411313238\n",
      "refund -0.15687682863729926\n",
      "error -0.1551917638569165\n",
      "could -0.1526470532977449\n",
      "get -0.15216813883747626\n",
      "disappointed -0.15030281867095294\n",
      "first -0.1500816422869223\n",
      "common -0.14989199468579106\n",
      "gone -0.14985603083017696\n",
      "month -0.1483796892119938\n",
      "returned -0.1483318315480041\n",
      "recognize -0.14601319829327897\n",
      "weeks -0.14298280103731453\n",
      "happened -0.1410527722977929\n",
      "send -0.14072576198270728\n",
      "andisk -0.1407227641544129\n",
      "time -0.14035345786419304\n",
      "data -0.13966892076228035\n",
      "fter -0.13920108606345308\n",
      "randomly -0.13863759344512566\n",
      "fix -0.13821316244022988\n",
      "errors -0.13565528624768836\n",
      "write -0.13442955423594627\n",
      "maybe -0.13282257583754295\n",
      "went -0.12981730963468108\n",
      "read -0.12962013966984154\n",
      "phone -0.12784633911192023\n",
      "unexpectedly -0.12698096766151937\n"
     ]
    }
   ],
   "source": [
    "for i, v in zip(min_idx, min_vals):\n",
    "    print(INDEX_TO_WORDS.get(i), v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orks 0.09060671786018278\n",
      "space 0.08749376326345833\n",
      "great 0.08251692132871924\n",
      "price 0.0787778719229928\n",
      "reat 0.06913210679170727\n",
      "fast 0.0627791474576272\n",
      "works 0.06057109586026598\n",
      "storage 0.05501503482685981\n",
      "perfect 0.05317525603525928\n",
      "highly 0.051844085505744854\n",
      "tablet 0.04479536646755473\n",
      "perfectly 0.04408030291767827\n",
      "room 0.04405811047708518\n",
      "plenty 0.043249073929109136\n",
      "holds 0.04313806528229153\n",
      "pleased 0.042248100643867026\n",
      "ighly 0.042180160565504006\n",
      "anyone 0.04064572465927654\n",
      "extra 0.03800135669712892\n",
      "videos 0.03628034440382322\n",
      "fits 0.03486242319068984\n",
      "se 0.03384995699265955\n",
      "sing 0.03361487588347965\n",
      "xcellent 0.03320200337112696\n",
      "whatever 0.03255558953664474\n",
      "allows 0.03192851443907796\n",
      "plug 0.03189199954748366\n",
      "urface 0.03165714603980076\n",
      "comes 0.031132730461864058\n",
      "easy 0.031091367793607466\n",
      "capacity 0.030891750076552028\n",
      "ove 0.03064225242252348\n",
      "best 0.030235245905376382\n",
      "performed 0.029939881539453348\n",
      "lots 0.02992000265643504\n",
      "instantly 0.029615296660675475\n",
      "library 0.029539563366100117\n",
      "recommend 0.029436985793978274\n",
      "collection 0.02915729693006047\n",
      "rice 0.029046092725430014\n",
      "delay 0.028861731022286275\n",
      "love 0.028680315679690486\n",
      "ab 0.028367913753487354\n",
      "worry 0.028079997415494124\n",
      "complaints 0.027764396323411808\n",
      "nstalled 0.02753131969905038\n",
      "store 0.027407968961105172\n",
      "gives 0.027177325783013608\n",
      "ots 0.026869321975512544\n",
      "action 0.026750691705346653\n"
     ]
    }
   ],
   "source": [
    "for i, v in zip(max_idx, max_vals):\n",
    "    print(INDEX_TO_WORDS.get(i), v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How accurately can we predict the star score using these 100 words ? \n",
    "\n",
    "Use linear and lasso (normalized regression) to predict star score using words. There is no exact practical use for this, but it may be interesting to see how well we can explain star scores using these 100 words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = np.concatenate((min_idx, max_idx), axis = 0)\n",
    "\n",
    "X_train_mybag_small = X_train_mybag.tocsc()[:,indices]\n",
    "X_test_mybag_small = X_test_mybag.tocsc()[:,indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LassoModel = LassoLarsCV(cv=5).fit(X_train_mybag_small.toarray(), y_train)\n",
    "LinearModel = linear_model.LinearRegression().fit(X_train_mybag_small.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard deviation of star score is 1.002599213954883\n",
      "\n",
      "LASSO model has a R^2 score of 0.40167789135457 on the train set\n",
      "\n",
      "LASSO model has a mean absolute error of 0.4915773078270914 stars on the train set\n",
      "\n",
      "Linear model has a R^2 score of 0.40925105597620437 on the train set\n",
      "\n",
      "Linear model has a mean absolute error of 0.49683308541854165 stars on the train set\n"
     ]
    }
   ],
   "source": [
    "print('standard deviation of star score is %s' %\n",
    "     (y_train.std()))\n",
    "\n",
    "print('\\nLASSO model has a R^2 score of %s on the train set' %\n",
    "      (LassoModel.score(X_train_mybag_small, y_train)))\n",
    "\n",
    "LassoFit = LassoModel.predict(X_train_mybag_small)\n",
    "\n",
    "print('\\nLASSO model has a mean absolute error of %s stars on the train set' %\n",
    "     (mean_absolute_error(y_train, LassoFit)))\n",
    "\n",
    "print('\\nLinear model has a R^2 score of %s on the train set' %\n",
    "      (LinearModel.score(X_train_mybag_small, y_train)))\n",
    "\n",
    "LinearFit = LinearModel.predict(X_train_mybag_small)\n",
    "\n",
    "print('\\nLinear model has a mean absolute error of %s stars on the train set' %\n",
    "     (mean_absolute_error(y_train, LinearFit)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard deviation of star score is 0.9743537750680035\n",
      "\n",
      "LASSO model has a R^2 score of 0.3132934542711098 on the test set\n",
      "\n",
      "LASSO model has a mean absolute error of 0.5120160410658079 stars on the test set\n",
      "\n",
      "Linear model has a R^2 score of 0.29359871273188565 on the test set\n",
      "\n",
      "Linear model has a mean absolute error of 0.5255382210783378 stars on the test set\n"
     ]
    }
   ],
   "source": [
    "print('standard deviation of star score is %s' %\n",
    "     (y_test.std()))\n",
    "\n",
    "LassoFitTest = LassoModel.predict(X_test_mybag_small)\n",
    "\n",
    "print('\\nLASSO model has a R^2 score of %s on the test set' %\n",
    "      (r2_score(y_test, LassoFitTest)))\n",
    "\n",
    "print('\\nLASSO model has a mean absolute error of %s stars on the test set' %\n",
    "     (mean_absolute_error(y_test, LassoFitTest)))\n",
    "\n",
    "LinearFitTest = LinearModel.predict(X_test_mybag_small)\n",
    "\n",
    "print('\\nLinear model has a R^2 score of %s on the test set' %\n",
    "      (r2_score(y_test, LinearFitTest)))\n",
    "\n",
    "print('\\nLinear model has a mean absolute error of %s stars on the test set' %\n",
    "     (mean_absolute_error(y_test, LinearFitTest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster negative reviews (i.e. one-star reviews)\n",
    "\n",
    "Use facebook sentence embeddings to cluster one star reviews. It may be a way to synthesize the different groups of complaints or product issues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_star = sandisk['reviewText'][sandisk['overall'] >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the pre-trained sentence embedding model\n",
    "from InferSent.models import InferSent\n",
    "import torch\n",
    "V = 2\n",
    "MODEL_PATH = 'infersent%s.pkl' % V\n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': V}\n",
    "infersent = InferSent(params_model)\n",
    "infersent.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# upload fastText word vectors for use in InferSent model\n",
    "W2V_PATH = 'fastText/crawl-300d-2M.vec'\n",
    "infersent.set_w2v_path(W2V_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8513(/10186) words with w2v vectors\n",
      "Vocab size : 8513\n"
     ]
    }
   ],
   "source": [
    "infersent.build_vocab(one_star, tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert reviews into list representation to effectively run code\n",
    "reviews = [review for review in one_star]\n",
    "# convert reviews into sentence vector representaiton\n",
    "# this will take a while\n",
    "embeddings = infersent.encode(reviews, tokenize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit k-means, iterating through 1 to 50 centroids, then plot cost function over number of centroids \n",
    "# i.e. 'elbow method'\n",
    "# the inflection point may be the ideal number of clusters\n",
    "from scipy import cluster\n",
    "cluster_array = [cluster.vq.kmeans(embeddings, i) for i in range(1,50,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBb+ISMgo+EVEQub/Ay80G65zDIq1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# zoom in \n",
    "from matplotlib import pyplot\n",
    "pyplot.plot([var for (cent,var) in cluster_array])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngP8PnpRkep7ozCQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot([var for (cent,var) in cluster_array[0:10]])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit kmeans for 3 clusters, sklearn used instead of scipy because of familiarity\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeanModel = KMeans(n_clusters=3).fit(embeddings)\n",
    "kmeanModel.fit(embeddings)\n",
    "\n",
    "klabels = kmeanModel.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_1 = klabels == 0\n",
    "cluster_2 = klabels == 1\n",
    "cluster_3 = klabels == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf-idf vectorize text and then find out which n-grams are correlated with each cluster\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def tfidf_features(tokenized_text):\n",
    "    \"\"\"\n",
    "        X_train, X_val, X_test  samples        \n",
    "        return TF-IDF vectorized representation of each description and vocabulary\n",
    "    \"\"\"\n",
    "    # splits on character n-grams in the range\n",
    "    # then generates occurence counts of each character n-gram\n",
    "    # and then performs tf-idf transformation \n",
    "    tfidf_vectorizer = TfidfVectorizer(analyzer='word', ngram_range = (1,3)).fit(tokenized_text)\n",
    "    text_transformed = tfidf_vectorizer.transform(tokenized_text)\n",
    "    return text_transformed, tfidf_vectorizer.vocabulary_, tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# apply to our own tickets\n",
    "\n",
    "two_stars_less = sandisk['reviewText'][sandisk['overall'] <= 1]\n",
    "review_vectors, tfidf_vocab, feature_names = tfidf_features(one_star)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00s 0.09060671786018278\n",
      "000 pictures maybe 0.08749376326345833\n",
      "00 bucks 0.08251692132871924\n",
      "00 great 0.0787778719229928\n",
      "10 0.06913210679170727\n",
      "00 from 0.0627791474576272\n",
      "00 bucks but 0.06057109586026598\n",
      "000 0.05501503482685981\n",
      "10 am 0.05317525603525928\n",
      "10 flash 0.051844085505744854\n",
      "000 byte 0.04479536646755473\n",
      "0mb 0.04408030291767827\n",
      "10 and have 0.04405811047708518\n",
      "10 and now 0.043249073929109136\n",
      "10 inch 0.04313806528229153\n",
      "10 note and 0.042248100643867026\n",
      "10 sd card 0.042180160565504006\n",
      "10 billing reads 0.04064572465927654\n",
      "10 1mp camera 0.03800135669712892\n",
      "04 you have 0.03628034440382322\n",
      "10 microsdxc card 0.03486242319068984\n",
      "100 00 0.03384995699265955\n",
      "10 more for 0.03361487588347965\n",
      "10 to 15 0.03320200337112696\n",
      "100mb or so 0.03255558953664474\n",
      "10 reads are 0.03192851443907796\n",
      "10 sdhc 0.03189199954748366\n",
      "10 best bang 0.03165714603980076\n",
      "10 after 0.031132730461864058\n",
      "10 8gb21 mb 0.031091367793607466\n"
     ]
    }
   ],
   "source": [
    "# find n-grams with highest correlation with cluster 1\n",
    "correl_1 = [(n,np.corrcoef(np.asarray(review_vectors[:,n].todense()).reshape(-1), cluster_1)[0,1]) for n in range(len(feature_names))]\n",
    "index_1, correlation_1 = zip(*correl_1)\n",
    "correl_array_1 = np.array(list(correlation_1))\n",
    "max_idx = np.flip(np.argsort(correl_array)[-30:], axis = 0)\n",
    "max_vals = correl_array[max_idx]\n",
    "for i in max_idx: \n",
    "    print(feature_names[i], correl_array[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 0.3669235077817829\n",
      "card 0.2917890171857623\n",
      "that 0.24092812056563703\n",
      "to 0.23573494467304215\n",
      "but 0.20961207488139177\n",
      "the card 0.2065849344471741\n",
      "of 0.1815342454039137\n",
      "on 0.17321152217635602\n",
      "from 0.17119897245632804\n",
      "and 0.16424855895294602\n",
      "class 0.15738355933399434\n",
      "cards 0.15423704449533718\n",
      "when 0.15190634458841556\n",
      "that the 0.15092551534261314\n",
      "up 0.14897219142067064\n",
      "microsd 0.1457780021110869\n",
      "if 0.14452452362306736\n",
      "you 0.14435116272077994\n",
      "sandisk 0.1420796907473829\n",
      "64gb 0.14080488806346764\n",
      "on the 0.14027503096527205\n",
      "read 0.13990587785894\n",
      "class 10 0.13867145910987777\n",
      "or 0.13696882270554717\n",
      "this card 0.1360520019524393\n",
      "format 0.1354132584506488\n",
      "ve 0.13521275788207854\n",
      "which 0.1347433031016476\n",
      "only 0.13461032855718175\n",
      "of the 0.13363022156086585\n"
     ]
    }
   ],
   "source": [
    "# find n-grams with highest correlation with cluster 2\n",
    "correl_2 = [(n,np.corrcoef(np.asarray(review_vectors[:,n].todense()).reshape(-1), cluster_2)[0,1]) for n in range(len(feature_names))]\n",
    "index_2, correlation_2 = zip(*correl_2)\n",
    "correl_array_2 = np.array(list(correlation_2))\n",
    "max_idx_2 = np.flip(np.argsort(correl_array_2)[-30:], axis = 0)\n",
    "for i in max_idx_2: \n",
    "    print(feature_names[i], correl_array_2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no 0.3525587554743574\n",
      "problems 0.2263245835383771\n",
      "not 0.2235522119615029\n",
      "issues 0.21015305757894745\n",
      "no problems 0.2077686765395097\n",
      "no issues 0.16119163593234517\n",
      "never 0.14694225307542372\n",
      "to say 0.14639740473050475\n",
      "any 0.14560128658197144\n",
      "had no 0.1449213926008408\n",
      "had any 0.14093926964452605\n",
      "complaints 0.13967233458528994\n",
      "not much 0.13818090985151632\n",
      "had 0.1367448081779986\n",
      "problem 0.1290643995810422\n",
      "any issues 0.12749825434060727\n",
      "much to 0.12479315904715632\n",
      "problems with 0.12465600028177795\n",
      "have had no 0.1218007345178071\n",
      "no complaints 0.12092516699795874\n",
      "issues with 0.11417716441056214\n",
      "had no problems 0.11413724768804154\n",
      "much to say 0.11280551068681031\n",
      "so far 0.1118710710150486\n",
      "have had 0.11071115522325364\n",
      "far 0.1085475229811124\n",
      "have not 0.1076261792647705\n",
      "and have 0.10674615236708093\n",
      "not much to 0.10669044454669031\n",
      "had any issues 0.10650956505080347\n"
     ]
    }
   ],
   "source": [
    "# find n-grams with highest correlation with cluster 3\n",
    "correl_3 = [(n,np.corrcoef(np.asarray(review_vectors[:,n].todense()).reshape(-1), cluster_3)[0,1]) for n in range(len(feature_names))]\n",
    "index_3, correlation_3 = zip(*correl_3)\n",
    "correl_array_3 = np.array(list(correlation_3))\n",
    "max_idx_3 = np.flip(np.argsort(correl_array_3)[-30:], axis = 0)\n",
    "for i in max_idx_3: \n",
    "    print(feature_names[i], correl_array_3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to a csv file\n",
    "\n",
    "one_star_df = sandisk[sandisk['overall'] <= 1].reset_index()\n",
    "one_star_df['cluster'] = pd.Series(klabels)\n",
    "one_star_df.sort_values(by='cluster', ascending = False).to_csv('KMeans_Facebook_Vectors.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save = one_star_df.sort_values(by='cluster')\n",
    "\n",
    "to_save.to_excel('Facebook_Clustering_Nov_six_clusters.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Clusters in 3D\n",
    "\n",
    "We can get an idea of how the clusters look in space by reducing our >4000 dimensions of the embeddings through PCA and labeling our clusters. This has been useful in the past while trying to tune parameters and see how well the clusters fit the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=300)\n",
    "reduced_infersent = pca.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(i) for i in set(klabels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-eba0b3c777d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m layout = Layout(showlegend=True,\n\u001b[1;32m     27\u001b[0m                 scene=Scene(xaxis=dict(title='Principle Component 1'),\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Data' is not defined"
     ]
    }
   ],
   "source": [
    "# Make a 3D plot\n",
    "import plotly.offline as off\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "traces = []\n",
    "for i in set(klabels):\n",
    "\n",
    "    trace = go.Scatter3d(\n",
    "        x=reduced_infersent[klabels==i,0],\n",
    "        y=reduced_infersent[klabels==i,1],\n",
    "        z=reduced_infersent[klabels==i,2],\n",
    "        text = one_star[klabels==i],\n",
    "        mode='markers',\n",
    "        name=str(i),\n",
    "        hoverinfo = 'text+name',\n",
    "        marker=dict(\n",
    "            size=12,\n",
    "            line=dict(\n",
    "                color='rgba(217, 217, 217, 0.14)',\n",
    "                width=0.5),\n",
    "            opacity=0.3))\n",
    "    traces.append(trace)\n",
    "\n",
    "\n",
    "data = Data(traces)\n",
    "layout = Layout(showlegend=True,\n",
    "                scene=Scene(xaxis=dict(title='Principle Component 1'),\n",
    "                yaxis=dict(title='Principle Component 2'),\n",
    "                zaxis=dict(title='Principle Component 3'),))\n",
    "\n",
    "\n",
    "fig = Figure(data=data, layout=layout)\n",
    "off.plot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_\\']')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "\n",
    "def text_prepare(text):    \n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string pre-processed \n",
    "        1. converting to lower-case\n",
    "        2. replace special characters with a space\n",
    "        3. remove othe symbols\n",
    "        4. remove stopwords\n",
    "    \"\"\"\n",
    "    text = re.sub(REPLACE_BY_SPACE_RE, ' ', text)\n",
    "    text = re.sub(BAD_SYMBOLS_RE, '', text)\n",
    "    text = text.lower()\n",
    "    text = [word for word in tokenizer.tokenize(text) if word not in STOPWORDS]\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "def text_splitter(texts):\n",
    "    split_texts = [tokenizer.tokenize(text) for text in texts]\n",
    "    return split_texts\n",
    "def dict_counter(split_texts):\n",
    "    # split, then flatten the nested list of texts\n",
    "    flattened_list = [word for text in split_texts for word in text]\n",
    "    # init the dict\n",
    "    words_counts_dict = dict()\n",
    "    for word in flattened_list: \n",
    "        # if there is no key, get will return 0 (second argument default = 0), and then add 1 \n",
    "        # if there is a pre-existing key, it will add 1 to the pre-existing number\n",
    "        # the loop loops through every word occurence\n",
    "        words_counts_dict[word] = words_counts_dict.get(word, 0) + 1\n",
    "    return words_counts_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return tokenizer.tokenize(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess_split(text):\n",
    "    text = re.sub(REPLACE_BY_SPACE_RE, ' ', text)\n",
    "    text = re.sub(BAD_SYMBOLS_RE, '', text)\n",
    "    text = text.lower()\n",
    "    text = lemmatize_stemming(text)\n",
    "    text = [word for word in text if word not in STOPWORDS]\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['like', 'green', 'eggs', 'ham', 'year', \"n't\", 'like']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_split('I like green eggs and ham, but last year I didn\\'t like them')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gensim_dict = gensim.corpora.Dictionary(split_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gensim_dict.filter_extremes(keep_n=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gensim_bow_corpus = [gensim_dict.doc2bow(review) for review in split_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word',       \n",
    "                             min_df=10,                        # minimum reqd occurences of a word \n",
    "                             stop_words='english',             # remove stop words\n",
    "                             lowercase=True,                   # convert all words to lowercase\n",
    "                             token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3\n",
    "                             max_features=3000,             # max number of uniq words\n",
    "                            )\n",
    "\n",
    "data_vectorized = vectorizer.fit_transform(prepared_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"search_params = {'n_components': [3,6,9,12,15,18,21,24,27,30], 'learning_decay': [.5, .7, .9]}\\nmodel = GridSearchCV(lda_model, param_grid = search_params)\\n\\ndocvecs = model.fit(data_vectorized)\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "from gensim.sklearn_api import LdaTransformer\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Reduce each document to 2 dimensions (topics) using the sklearn interface.\n",
    "lda_model = LatentDirichletAllocation(n_components=20,               # Number of topics\n",
    "                                      max_iter=10,               # Max learning iterations\n",
    "                                      learning_method='online',   \n",
    "                                      random_state=100,          # Random state\n",
    "                                      batch_size=128,            # n docs in each learning iter\n",
    "                                      evaluate_every = -1,       # compute perplexity every n iters, default: Don't\n",
    "                                      n_jobs = -1,               # Use all available CPUs\n",
    "                                     )\n",
    "\n",
    "'''search_params = {'n_components': [3,6,9,12,15,18,21,24,27,30], 'learning_decay': [.5, .7, .9]}\n",
    "model = GridSearchCV(lda_model, param_grid = search_params)\n",
    "\n",
    "docvecs = model.fit(data_vectorized)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-9e50351ed853>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Best Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_lda_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Model Parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best Model's Params: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "'''# Best Model\n",
    "best_lda_model = model.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''pyLDAvis.enable_notebook()\n",
    "panel = pyLDAvis.sklearn.prepare(best_lda_model, data_vectorized, vectorizer, mds='tsne')\n",
    "panel'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Topic-Keyword Matrix\n",
    "df_topic_keywords = pd.DataFrame(best_lda_model.components_)\n",
    "\n",
    "# Assign Column and Index\n",
    "df_topic_keywords.columns = vectorizer.get_feature_names()\n",
    "df_topic_keywords.index = topicnames\n",
    "\n",
    "# View\n",
    "df_topic_keywords.head()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = lda_cust(4, max_iter = 30)\n",
    "b = a.fit(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting LDA model for 3 topics . . . \n",
      "LDA for 3 topics is done\n",
      "fitting LDA model for 4 topics . . . \n",
      "LDA for 4 topics is done\n",
      "fitting LDA model for 5 topics . . . \n",
      "LDA for 5 topics is done\n",
      "fitting LDA model for 6 topics . . . \n",
      "LDA for 6 topics is done\n",
      "fitting LDA model for 7 topics . . . \n",
      "LDA for 7 topics is done\n",
      "fitting LDA model for 8 topics . . . \n",
      "LDA for 8 topics is done\n",
      "fitting LDA model for 9 topics . . . \n",
      "LDA for 9 topics is done\n",
      "fitting LDA model for 10 topics . . . \n",
      "LDA for 10 topics is done\n"
     ]
    }
   ],
   "source": [
    "def lda_cust(n, max_iter = 30): \n",
    "    model = LatentDirichletAllocation(n_components=n,               # Number of topics\n",
    "                                      max_iter=10, # Max learning iterations\n",
    "                                      learning_decay = 0.5, \n",
    "                                      learning_method='online',   \n",
    "                                      random_state=100,          # Random state\n",
    "                                      batch_size=128,            # n docs in each learning iter\n",
    "                                      evaluate_every = -1,       # compute perplexity every n iters, default: Don't\n",
    "                                      n_jobs = -1,               # Use all available CPUs\n",
    "                                     )\n",
    "    return model\n",
    "\n",
    "names = ['lda_model_{}'.format(x) for x in range(3,11)]\n",
    "numbers = range(3,11)\n",
    "\n",
    "lda_model_dict = {}\n",
    "for model, number in zip (names, numbers): \n",
    "    print('fitting LDA model for {} topics . . . '.format(number))\n",
    "    lda_model_dict[model] = lda_cust(number, max_iter = 30).fit(data_vectorized)\n",
    "    print('LDA for {} topics is done'.format(number))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lda_model_3', 'lda_model_4', 'lda_model_5', 'lda_model_6', 'lda_model_7', 'lda_model_8', 'lda_model_9', 'lda_model_10'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.5,\n",
       "             learning_method='online', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=4, n_jobs=-1, n_topics=None, perp_tol=0.1,\n",
       "             random_state=100, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model_dict['lda_model_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alex.Shypula@ibm.com/anaconda3/lib/python3.6/site-packages/pyLDAvis/_prepare.py:257: FutureWarning:\n",
      "\n",
      "Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el823644584111364998494441\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el823644584111364998494441_data = {\"mdsDat\": {\"x\": [-30.717445373535156, 91.19690704345703, 1.3318208456039429, 94.87906646728516, -36.678524017333984, -112.02374267578125], \"y\": [85.74382781982422, -92.195068359375, -23.032026290893555, 41.06304168701172, -129.8704833984375, -19.89765739440918], \"topics\": [1, 2, 3, 4, 5, 6], \"cluster\": [1, 1, 1, 1, 1, 1], \"Freq\": [24.07710233253113, 23.529213209485082, 20.37639058382402, 18.288323313598266, 8.497196742259437, 5.231773818302066]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\"], \"Freq\": [1649.0, 581.0, 838.0, 727.0, 4405.0, 466.0, 260.0, 403.0, 730.0, 595.0, 1216.0, 584.0, 468.0, 721.0, 283.0, 1133.0, 374.0, 1163.0, 792.0, 334.0, 152.0, 284.0, 344.0, 309.0, 504.0, 926.0, 451.0, 251.0, 462.0, 363.0, 334.14886597223455, 308.25883672011093, 246.59127150455583, 192.67829151102868, 138.0760447174962, 135.2911446093898, 134.0610406006988, 130.85848749324336, 121.2195589686494, 97.65323045751556, 86.65945169009967, 85.3640584251843, 84.36132102091035, 80.64882697754884, 79.68927792660625, 75.09563113131094, 74.4540140570498, 70.83782083115793, 67.79207671001889, 66.15024196676598, 62.259392946300764, 61.35252634224223, 57.062739622457535, 57.13267495847554, 54.13264939093045, 53.082212308701514, 51.80404107918485, 50.856804511937916, 49.934530157887835, 49.66501464606228, 265.3768268247606, 71.01885672989002, 534.5228950908046, 158.54268894147864, 363.658407725495, 108.54435847702983, 541.6779059422355, 487.665779219307, 525.3904197533486, 288.91107404350925, 291.71300614502695, 226.7721242957383, 188.8990142930992, 432.8713841757797, 210.16536310420597, 366.37127816096984, 281.9358618090507, 387.80270783509064, 350.27060937470617, 120.37161192602763, 287.3315906169745, 598.3900268472262, 175.27624854016435, 188.34849381819828, 217.65755304711382, 193.86045946850973, 161.2131058614615, 139.11389931028685, 138.1437933892912, 236.65079830998909, 202.38020500844053, 159.74564106593573, 159.65730100990726, 113.22350042343385, 106.63243538388434, 102.11452849500981, 100.96983400927539, 99.64014997066923, 91.83181777726278, 82.31017937758259, 80.27723015105249, 80.02858472324466, 76.72200459044507, 74.27088428205653, 71.33105915734532, 70.82495058902299, 66.69476126737389, 64.42769685307283, 60.24262724387287, 59.419862285049945, 57.315221031389996, 56.77521565564612, 55.275340916064906, 54.46329993386801, 53.55112580969496, 48.93029880240517, 47.71844412609905, 47.49771128740059, 46.913169445154516, 67.67578913726683, 294.7828528006602, 137.17485108009487, 350.8964951877509, 165.8369229630812, 263.84563216360755, 2136.0181949328203, 238.0823234325095, 190.55772138949763, 493.7706257591558, 263.2898866321816, 230.27561672969756, 89.35450010720646, 226.0104618747929, 355.4915857544249, 89.18708862282584, 191.27307900209635, 181.42125135957957, 232.27048585611, 115.00262393511693, 192.58880493598198, 142.13346981568478, 130.36517739650762, 240.23457016105917, 152.51348188776433, 150.08888239793856, 129.3846118398024, 134.6302658744793, 131.17437008908425, 580.7313372880074, 402.77788130988597, 283.25236106971954, 218.14394080908224, 180.4333309443382, 145.13558702931257, 131.24612377942347, 123.81974111745531, 112.41512651129278, 101.2328536200863, 98.9075187199489, 88.74219261691181, 86.70752983114338, 85.9883747302337, 82.00848924083935, 79.75904997885192, 76.81297024217508, 64.0503294380468, 63.007772445535586, 59.33330718147062, 55.27393821585136, 53.416124354531014, 51.783675186662286, 46.61036661955201, 46.12130039551537, 44.99232299230385, 43.635520120595594, 43.618806289970266, 42.24315596532295, 41.269939175857026, 611.9923064946515, 681.2907792866602, 66.54093430695342, 449.24578468184285, 471.7367494008724, 899.1097744151102, 119.93231901759884, 243.81691313396504, 194.1447529421069, 106.8730788930514, 117.38159198757035, 254.95485001224606, 427.21142183928094, 416.59025177832746, 789.9146189573092, 335.16990626372836, 191.20509775530627, 359.43878367032744, 119.7944417548214, 207.0086813388881, 178.79983496775083, 134.66732454296985, 207.82139241766447, 161.42728886459926, 143.13258434462188, 141.0693815612134, 250.84290093709592, 147.7482291176843, 128.9021769968069, 163.8691639520095, 94.86178319161102, 82.60446821708565, 69.09859352009302, 69.02056844578743, 69.04669099414033, 66.13045584482944, 64.05195501601709, 63.62269872692238, 62.89480147038452, 57.25022166296136, 55.5883609636238, 55.3325130174072, 54.69657819468932, 54.17854589316026, 52.60228327897094, 52.58871660996589, 52.25477480564888, 51.60754174293041, 49.34062503381332, 49.65315423193528, 48.99284094140276, 48.63335297822298, 48.38483903789452, 46.75438507196415, 45.545641745714825, 44.77249094231259, 106.99221866224107, 103.13343250567658, 276.2447696093047, 133.3763038914082, 183.03869369421068, 237.2680924555354, 184.65265831350294, 203.86926434200288, 472.6302424157893, 212.40791072729291, 349.2634102134925, 793.231784580395, 241.74920026749555, 310.78106103790236, 183.23836360588598, 217.88132483938895, 104.95302864521788, 140.98241751053948, 147.89323790058484, 240.32253683915647, 173.28723933961285, 184.33439069307002, 140.89392870708238, 116.22579401699058, 115.86245771343816, 153.55630260928197, 134.9956402099274, 145.22243217975407, 114.6243326793163, 259.20913327025664, 116.23906888915052, 114.40685942539932, 109.06667086273201, 105.5216845328666, 97.92795259398748, 90.2658220698917, 77.36926659722921, 65.9212872519375, 64.22965606979511, 62.748553957882464, 55.075972868705755, 53.94316346819367, 52.75891963647026, 51.12494897806066, 48.30494509860392, 44.49469310816245, 42.660586278764924, 40.74078348687849, 39.272882099772595, 39.16858645454869, 38.89842477997802, 34.123704992100606, 31.870257213654796, 30.95575297391124, 29.420701585603265, 27.968818315779377, 27.837762770212855, 26.427320487916965, 26.536086274345585, 215.16394904919682, 48.57493679607415, 46.614658715666536, 112.18289857964409, 112.62938510858646, 113.01620791249711, 210.66317951534214, 68.04935045550971, 106.24019221375812, 144.02037931369497, 158.73180782759275, 130.31739337416903, 125.24295342138376, 255.518902999722, 213.96192189077053, 119.01575295683024, 86.9362050606365, 103.70395792541144, 73.7985710236197, 76.45265655270669, 71.53512225223808, 87.96788732775234, 151.28937454134737, 134.68799849154252, 113.39872561164424, 99.99653014623551, 71.23349358060038, 69.60062631612765, 69.31010384253815, 68.15019322337002, 67.39208805584535, 65.86484861849604, 63.18350570740102, 58.63095365776565, 58.65194457986945, 54.82254030840556, 54.147928010350036, 52.05223331806514, 51.1396513957245, 49.4526175347776, 48.32099988188764, 80.87610353775214, 46.66183032199163, 46.22199814123907, 42.03818643768054, 39.86735436908239, 39.66874478705352, 39.65388100557559, 39.047567319821624, 38.868439441969706, 38.4031009130858, 37.2548632938846, 86.86029285140215, 51.004823318220616, 49.13026541770178, 42.97110884741633, 39.847278294232474], \"Term\": [\"phone\", \"music\", \"alaxy\", \"amsung\", \"card\", \"space\", \"reat\", \"ote\", \"good\", \"speed\", \"memory\", \"tablet\", \"camera\", \"storage\", \"lot\", \"works\", \"pictures\", \"great\", \"price\", \"write\", \"galaxy\", \"movies\", \"dont\", \"class\", \"product\", \"cards\", \"got\", \"working\", \"work\", \"say\", \"write\", \"class\", \"quality\", \"size\", \"better\", \"nice\", \"ery\", \"buying\", \"high\", \"advertised\", \"cheaper\", \"wrong\", \"highly\", \"come\", \"job\", \"standard\", \"record\", \"actually\", \"digital\", \"super\", \"value\", \"stores\", \"sec\", \"youre\", \"regular\", \"especially\", \"start\", \"described\", \"pro\", \"priced\", \"speeds\", \"flash\", \"speed\", \"best\", \"camera\", \"excellent\", \"price\", \"good\", \"fast\", \"adapter\", \"product\", \"recommend\", \"transfer\", \"great\", \"buy\", \"use\", \"micro\", \"memory\", \"works\", \"products\", \"cards\", \"card\", \"video\", \"like\", \"anisk\", \"storage\", \"read\", \"need\", \"device\", \"oro\", \"ltra\", \"hat\", \"reader\", \"complaints\", \"free\", \"emory\", \"hey\", \"took\", \"ero\", \"writing\", \"test\", \"hours\", \"recommended\", \"service\", \"sing\", \"expect\", \"star\", \"lack\", \"wouldnt\", \"cam\", \"customer\", \"transfers\", \"transferred\", \"lose\", \"ead\", \"reformatted\", \"backup\", \"noticed\", \"included\", \"rating\", \"icro\", \"tried\", \"work\", \"ard\", \"format\", \"card\", \"andisk\", \"lass\", \"cards\", \"files\", \"data\", \"indows\", \"read\", \"anisk\", \"review\", \"worked\", \"problem\", \"micro\", \"old\", \"using\", \"mazon\", \"devices\", \"use\", \"video\", \"got\", \"computer\", \"new\", \"time\", \"music\", \"ote\", \"movies\", \"store\", \"purchase\", \"room\", \"plenty\", \"101\", \"urface\", \"said\", \"hard\", \"internal\", \"lots\", \"play\", \"second\", \"fit\", \"instead\", \"expand\", \"install\", \"errors\", \"microsd\", \"transferring\", \"loaded\", \"added\", \"ook\", \"external\", \"storing\", \"plus\", \"popped\", \"decent\", \"amsung\", \"alaxy\", \"immediately\", \"tablet\", \"storage\", \"phone\", \"recognized\", \"pictures\", \"videos\", \"installed\", \"apps\", \"space\", \"works\", \"great\", \"card\", \"use\", \"orks\", \"memory\", \"ndroid\", \"bought\", \"problems\", \"photos\", \"fast\", \"files\", \"purchased\", \"new\", \"working\", \"issue\", \"ood\", \"sure\", \"big\", \"run\", \"awesome\", \"black\", \"ave\", \"ago\", \"died\", \"past\", \"order\", \"lso\", \"gopro\", \"ould\", \"isnt\", \"look\", \"mobile\", \"tiny\", \"expensive\", \"orked\", \"error\", \"tell\", \"half\", \"access\", \"soon\", \"items\", \"wish\", \"fact\", \"cell\", \"lost\", \"say\", \"think\", \"months\", \"fine\", \"far\", \"issues\", \"phone\", \"product\", \"works\", \"card\", \"good\", \"great\", \"like\", \"anisk\", \"reliable\", \"problem\", \"time\", \"memory\", \"bought\", \"price\", \"problems\", \"really\", \"mazon\", \"alaxy\", \"using\", \"cards\", \"buy\", \"reat\", \"worth\", \"64gb\", \"days\", \"running\", \"stuff\", \"taking\", \"save\", \"plug\", \"pics\", \"fits\", \"download\", \"amazon\", \"lag\", \"later\", \"tons\", \"wifes\", \"delete\", \"drives\", \"bucks\", \"shooting\", \"option\", \"taken\", \"seconds\", \"told\", \"nly\", \"lenty\", \"thinking\", \"insert\", \"genuine\", \"lot\", \"worry\", \"load\", \"needed\", \"want\", \"extra\", \"space\", \"chip\", \"know\", \"dont\", \"got\", \"pictures\", \"need\", \"phone\", \"memory\", \"worked\", \"photos\", \"camera\", \"perfectly\", \"time\", \"buy\", \"card\", \"galaxy\", \"going\", \"replacement\", \"failed\", \"player\", \"tested\", \"ablet\", \"gigs\", \"replace\", \"samsung\", \"sus\", \"trust\", \"left\", \"defective\", \"additional\", \"sent\", \"till\", \"saying\", \"tests\", \"warranty\", \"hope\", \"hats\", \"ony\", \"completely\", \"send\", \"thumb\", \"goes\", \"single\", \"feel\", \"addition\", \"item\", \"return\", \"android\", \"day\", \"bad\"], \"Total\": [1649.0, 581.0, 838.0, 727.0, 4405.0, 466.0, 260.0, 403.0, 730.0, 595.0, 1216.0, 584.0, 468.0, 721.0, 283.0, 1133.0, 374.0, 1163.0, 792.0, 334.0, 152.0, 284.0, 344.0, 309.0, 504.0, 926.0, 451.0, 251.0, 462.0, 363.0, 334.9877139119301, 309.11161562868284, 247.42776795448705, 193.51773213004068, 138.91541945960836, 136.13033179452202, 134.90246373741365, 131.70522772734077, 122.05618086940092, 98.48986150206639, 87.49794732621055, 86.20281571323977, 85.19867971486373, 81.49328052211304, 80.5274451606424, 75.93314917888972, 75.2966350733932, 71.67881952797318, 68.62985810996521, 66.99156217894568, 63.09509349212168, 62.191465182171605, 57.89848910649174, 57.975035467462384, 54.97165045214975, 53.922220599152986, 52.65188235179436, 51.69317160395495, 50.77006266280773, 50.50243134768194, 272.45346873679216, 72.286466378501, 595.7660039455594, 174.041553846119, 468.03247341361566, 120.36730694346281, 792.9111158955659, 730.0894329200096, 818.6656843455795, 456.8688752971367, 504.79563264143206, 369.7599239779626, 303.0070442858977, 1163.6363423364257, 396.830746917569, 1023.0755558667026, 672.1572613143857, 1216.3911092138453, 1133.7905407836317, 167.1320226481823, 926.8347195006003, 4405.700296503821, 402.0053863798913, 490.0949549268127, 791.5405098561836, 721.0796426347869, 397.6010834964789, 378.975432474023, 315.3443230500944, 237.48125154319948, 203.21247961620168, 160.5809184315854, 160.50873664716414, 114.05959211911052, 107.4665716396155, 102.9450830246709, 101.80317147722776, 100.4740630649757, 92.6609691486084, 83.14060269951148, 81.10819229445742, 80.85958676010212, 77.55562480858637, 75.10423776764617, 72.16939439555689, 71.6604261234557, 67.52661599902561, 65.25817629180992, 61.077201361680835, 60.25354758237045, 58.1480233065797, 57.609482898017234, 56.10766549978905, 55.30535486697175, 54.382323590549376, 49.76305182564973, 48.55354128157361, 48.33847916198159, 47.746265124403905, 70.91649323730448, 352.2594436346064, 155.51261696145815, 462.2356671865662, 200.01779411089313, 358.6456294663123, 4405.700296503821, 344.87272144684994, 264.4720875807516, 926.8347195006003, 425.3869655021543, 385.90973286862254, 103.95916492407217, 397.6010834964789, 791.5405098561836, 104.14156997783698, 396.82936375563617, 364.289498003118, 672.1572613143857, 169.58958256715528, 525.9977582235134, 291.71565174155074, 241.79072183019048, 1023.0755558667026, 402.0053863798913, 451.4733671288127, 266.9511211389708, 395.3721646265273, 409.77324539916526, 581.562890120595, 403.6786655175039, 284.08347015536765, 218.97636398159338, 181.2713830068728, 145.9667853615103, 132.0776817351381, 124.65076172331845, 113.24572127661617, 102.08547370242576, 99.74476108917752, 89.57362177110956, 87.53990778515794, 86.82435713808592, 82.85043263430994, 80.59320678456396, 77.65656498377984, 64.88123385180907, 63.83786822448079, 60.17584048475552, 56.11183273506273, 54.25368908964362, 52.6164878512172, 47.4407123488244, 46.95446767137713, 45.82373250493287, 44.467273893121096, 44.46335868511816, 43.080184416307, 42.11339232781992, 727.4437260993052, 838.3993355473061, 70.09569544281455, 584.0104364473069, 721.0796426347869, 1649.3022251258135, 149.84958811046462, 374.79952042509797, 290.21751349234415, 134.0517345645405, 152.36223317332053, 466.28159108199657, 1133.7905407836317, 1163.6363423364257, 4405.700296503821, 1023.0755558667026, 382.1705609257113, 1216.3911092138453, 176.1248429780695, 615.4113170068138, 453.3105838229183, 240.4019657715192, 818.6656843455795, 425.3869655021543, 308.94710052613397, 395.3721646265273, 251.67485529437047, 148.58214102250201, 129.73414840691268, 164.93526369588676, 95.69713114895359, 83.44421806601339, 69.93119095299701, 69.8524712722381, 69.88060335555542, 66.9617559859022, 64.88368669684603, 64.45789678366076, 63.73178358113526, 58.08267267718475, 56.42070551419017, 56.1666075798937, 55.5308638314686, 55.01663442135246, 53.434876350286686, 53.42124075524156, 53.08751548372521, 52.439780084959075, 50.17219857617915, 50.49478772379807, 49.82767568114441, 49.468727659242774, 49.21879538161206, 47.58653756004764, 46.377813356117976, 45.60762038296442, 110.82423547866377, 113.35016570599227, 363.14503584190703, 166.4860279145303, 264.33228737258725, 382.4347639368016, 366.0300733977863, 443.156575749627, 1649.3022251258135, 504.79563264143206, 1133.7905407836317, 4405.700296503821, 730.0894329200096, 1163.6363423364257, 490.0949549268127, 791.5405098561836, 197.1104726148217, 364.289498003118, 409.77324539916526, 1216.3911092138453, 615.4113170068138, 792.9111158955659, 453.3105838229183, 285.8553031165762, 291.71565174155074, 838.3993355473061, 525.9977582235134, 926.8347195006003, 396.830746917569, 260.03581162803886, 117.06843039724998, 115.23784592146448, 109.8999457471053, 106.35334485397138, 98.75446795286418, 91.09320461582587, 78.19634807489379, 66.7514057331909, 65.05639946644756, 63.575208102848926, 55.904190852735994, 54.772708692352374, 53.58842821541975, 51.95428737260623, 49.12994944106196, 45.32116375799268, 43.490528773086076, 41.57637998068434, 40.101536731689976, 39.997706941812396, 39.72836488977464, 34.95136983854508, 32.69982069978528, 31.784812525834056, 30.248927972090293, 28.796953644945688, 28.665264195727403, 27.258627482812052, 27.371854042046404, 283.5606349483425, 57.57363982326995, 56.25957003125864, 178.75227581944904, 180.83900427895213, 192.61256234225053, 466.28159108199657, 97.3276763037394, 194.04325449668627, 344.36128326502853, 451.4733671288127, 374.79952042509797, 378.975432474023, 1649.3022251258135, 1216.3911092138453, 396.82936375563617, 240.4019657715192, 468.03247341361566, 237.39951524247482, 409.77324539916526, 396.830746917569, 4405.700296503821, 152.10624448950458, 135.50765619353038, 114.21549693882292, 100.81353812045265, 72.05070301731574, 70.42038216840169, 70.12732654891185, 68.96976666305834, 68.21033870690873, 66.68090916860487, 64.00123797447752, 59.450878613670326, 59.474313551918875, 55.64097909548164, 54.96751026705138, 52.86909790202889, 51.95866611747418, 50.27288275333862, 49.14083397591611, 82.24914375443392, 47.480568220255584, 47.039676700366826, 42.85463329083118, 40.685788535092264, 40.48607444301364, 40.480038248060886, 39.867539628382474, 39.68957695903382, 39.223356359828465, 38.07567475967795, 118.71080976618794, 79.18135168535125, 82.16370004417476, 99.12769259255785, 146.74702120038285], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.4214, 1.4211, 1.4205, 1.4196, 1.4178, 1.4177, 1.4177, 1.4175, 1.417, 1.4154, 1.4143, 1.4141, 1.414, 1.4135, 1.4134, 1.4128, 1.4127, 1.4121, 1.4116, 1.4113, 1.4106, 1.4103, 1.4094, 1.4093, 1.4085, 1.4082, 1.4077, 1.4076, 1.4073, 1.4072, 1.3976, 1.4062, 1.3154, 1.3306, 1.1716, 1.3205, 1.0429, 1.0204, 0.9804, 0.9656, 0.8755, 0.935, 0.9514, 0.435, 0.7883, 0.397, 0.5551, 0.2808, 0.2493, 1.0957, 0.2528, -0.5725, 0.5938, 0.4676, 0.1329, 0.1103, 0.5212, 0.4217, 0.5985, 1.4434, 1.4428, 1.4417, 1.4416, 1.4396, 1.4391, 1.4388, 1.4387, 1.4386, 1.4379, 1.4369, 1.4366, 1.4366, 1.4361, 1.4358, 1.4352, 1.4352, 1.4345, 1.4341, 1.4332, 1.433, 1.4325, 1.4323, 1.432, 1.4316, 1.4315, 1.4301, 1.4296, 1.4294, 1.4293, 1.4002, 1.2688, 1.3215, 1.1713, 1.2595, 1.14, 0.723, 1.0764, 1.1191, 0.8172, 0.9672, 0.9306, 1.2955, 0.8821, 0.6464, 1.2919, 0.7171, 0.7498, 0.3843, 1.0585, 0.4422, 0.7279, 0.8292, -0.002, 0.4777, 0.3456, 0.7227, 0.3696, 0.3079, 1.5894, 1.5886, 1.5879, 1.587, 1.5862, 1.5851, 1.5845, 1.5841, 1.5834, 1.5824, 1.5824, 1.5815, 1.5812, 1.5811, 1.5806, 1.5804, 1.5799, 1.5779, 1.5777, 1.5767, 1.5757, 1.5752, 1.5748, 1.5731, 1.5729, 1.5725, 1.5719, 1.5716, 1.5712, 1.5706, 1.418, 1.3833, 1.5387, 1.3284, 1.1665, 0.9841, 1.3681, 1.1608, 1.1888, 1.3642, 1.33, 0.9871, 0.6148, 0.5636, -0.1279, 0.4749, 0.8983, 0.3717, 1.2054, 0.5013, 0.6605, 1.0113, 0.2198, 0.6218, 0.8214, 0.5602, 1.6956, 1.6933, 1.6925, 1.6924, 1.6901, 1.6888, 1.6869, 1.6869, 1.6869, 1.6864, 1.686, 1.6859, 1.6857, 1.6845, 1.684, 1.6839, 1.6838, 1.6836, 1.6832, 1.6832, 1.6831, 1.6829, 1.6822, 1.6821, 1.682, 1.6819, 1.6818, 1.6813, 1.6808, 1.6804, 1.6637, 1.6044, 1.4254, 1.4772, 1.3314, 1.2215, 1.0147, 0.9225, 0.4491, 0.8333, 0.5214, -0.0156, 0.5936, 0.3787, 0.7151, 0.4089, 1.0687, 0.7496, 0.6798, 0.0772, 0.4316, 0.2399, 0.5303, 0.799, 0.7755, 0.0015, 0.3389, -0.1546, 0.4571, 2.4622, 2.4583, 2.4582, 2.4578, 2.4576, 2.457, 2.4563, 2.4548, 2.4529, 2.4526, 2.4523, 2.4505, 2.4502, 2.4498, 2.4493, 2.4485, 2.447, 2.4462, 2.4451, 2.4446, 2.4445, 2.4443, 2.4415, 2.4397, 2.439, 2.4377, 2.4363, 2.4361, 2.4345, 2.4344, 2.1894, 2.2955, 2.2774, 1.9996, 1.9919, 1.9323, 1.6709, 2.1076, 1.8631, 1.5937, 1.4201, 1.409, 1.3582, 0.6006, 0.7276, 1.2612, 1.4483, 0.9584, 1.297, 0.7865, 0.7521, -1.4482, 2.945, 2.9444, 2.9432, 2.9423, 2.939, 2.9387, 2.9387, 2.9385, 2.9384, 2.9381, 2.9376, 2.9365, 2.9365, 2.9356, 2.9354, 2.9348, 2.9345, 2.934, 2.9336, 2.9336, 2.933, 2.9329, 2.9312, 2.9301, 2.93, 2.9298, 2.9296, 2.9295, 2.9293, 2.9286, 2.638, 2.5106, 2.4362, 2.1145, 1.6468], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.1538, -4.2344, -4.4576, -4.7043, -5.0376, -5.0579, -5.0671, -5.0912, -5.1678, -5.3839, -5.5034, -5.5184, -5.5302, -5.5753, -5.5872, -5.6466, -5.6552, -5.705, -5.7489, -5.7734, -5.834, -5.8487, -5.9212, -5.92, -5.9739, -5.9935, -6.0179, -6.0363, -6.0546, -6.0601, -4.3842, -5.7024, -3.684, -4.8993, -4.0691, -5.2782, -3.6707, -3.7757, -3.7012, -4.2992, -4.2896, -4.5414, -4.7241, -3.8949, -4.6175, -4.0617, -4.3237, -4.0049, -4.1067, -5.1748, -4.3047, -3.5711, -4.799, -4.7271, -4.5824, -4.6982, -4.8826, -5.0301, -5.0371, -4.4758, -4.6322, -4.8688, -4.8693, -5.213, -5.273, -5.3162, -5.3275, -5.3408, -5.4224, -5.5318, -5.5569, -5.56, -5.6021, -5.6346, -5.675, -5.6821, -5.7422, -5.7768, -5.844, -5.8577, -5.8938, -5.9032, -5.93, -5.9448, -5.9617, -6.0519, -6.077, -6.0817, -6.094, -5.7276, -4.2561, -5.0211, -4.0818, -4.8313, -4.367, -2.2756, -4.4697, -4.6924, -3.7403, -4.3691, -4.5031, -5.4497, -4.5218, -4.0688, -5.4516, -4.6886, -4.7415, -4.4944, -5.1974, -4.6818, -4.9856, -5.072, -4.4607, -4.9151, -4.9311, -5.0795, -5.0398, -5.0658, -3.4342, -3.8001, -4.1521, -4.4133, -4.6031, -4.8208, -4.9214, -4.9796, -5.0763, -5.181, -5.2043, -5.3127, -5.3359, -5.3443, -5.3916, -5.4195, -5.4571, -5.6388, -5.6552, -5.7153, -5.7862, -5.8204, -5.8514, -5.9566, -5.9672, -5.992, -6.0226, -6.023, -6.055, -6.0783, -3.3818, -3.2745, -5.6007, -3.6909, -3.6421, -2.9971, -5.0115, -4.3021, -4.5299, -5.1268, -5.033, -4.2574, -3.7412, -3.7664, -3.1265, -3.9838, -4.5451, -3.9139, -5.0127, -4.4657, -4.6122, -4.8957, -4.4618, -4.7144, -4.8347, -4.8492, -4.1655, -4.6948, -4.8313, -4.5913, -5.1379, -5.2763, -5.4548, -5.456, -5.4556, -5.4987, -5.5307, -5.5374, -5.5489, -5.6429, -5.6724, -5.677, -5.6886, -5.6981, -5.7276, -5.7279, -5.7342, -5.7467, -5.7916, -5.7853, -5.7987, -5.806, -5.8112, -5.8454, -5.8716, -5.8888, -5.0176, -5.0543, -4.0691, -4.7972, -4.4807, -4.2212, -4.4719, -4.3729, -3.532, -4.3318, -3.8345, -3.0142, -4.2025, -3.9513, -4.4796, -4.3064, -5.0368, -4.7417, -4.6939, -4.2084, -4.5354, -4.4736, -4.7424, -4.9348, -4.938, -4.6563, -4.7851, -4.7121, -4.9487, -3.3662, -4.1682, -4.1841, -4.2319, -4.2649, -4.3396, -4.4211, -4.5752, -4.7354, -4.7614, -4.7847, -4.9151, -4.9359, -4.9581, -4.9896, -5.0463, -5.1285, -5.1706, -5.2166, -5.2533, -5.256, -5.2629, -5.3938, -5.4622, -5.4913, -5.5421, -5.5927, -5.5974, -5.6494, -5.6453, -3.5524, -5.0407, -5.0819, -4.2037, -4.1997, -4.1963, -3.5736, -4.7036, -4.2581, -3.9539, -3.8566, -4.0539, -4.0936, -3.3805, -3.558, -4.1446, -4.4587, -4.2823, -4.6225, -4.5872, -4.6536, -4.4469, -3.4197, -3.5359, -3.7079, -3.8337, -4.1729, -4.1961, -4.2003, -4.2171, -4.2283, -4.2512, -4.2928, -4.3676, -4.3672, -4.4347, -4.4471, -4.4866, -4.5043, -4.5378, -4.561, -4.0459, -4.5959, -4.6054, -4.7003, -4.7533, -4.7583, -4.7587, -4.7741, -4.7787, -4.7907, -4.8211, -3.9745, -4.5069, -4.5444, -4.6783, -4.7538]}, \"token.table\": {\"Topic\": [3, 5, 6, 4, 1, 1, 2, 4, 3, 6, 6, 1, 4, 2, 3, 4, 5, 2, 3, 4, 1, 2, 4, 6, 1, 2, 4, 3, 5, 2, 3, 4, 4, 2, 2, 4, 6, 1, 5, 1, 4, 4, 1, 2, 3, 4, 5, 6, 5, 1, 4, 5, 1, 2, 1, 5, 1, 2, 3, 4, 5, 1, 2, 4, 2, 4, 1, 4, 5, 6, 1, 1, 2, 6, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 6, 5, 3, 6, 5, 1, 1, 2, 3, 4, 1, 2, 4, 4, 1, 1, 2, 5, 5, 5, 2, 2, 2, 4, 3, 1, 1, 1, 2, 3, 2, 4, 3, 3, 5, 4, 6, 1, 3, 4, 1, 2, 3, 4, 5, 6, 2, 3, 2, 3, 4, 3, 5, 1, 5, 2, 3, 4, 2, 6, 5, 6, 6, 6, 1, 4, 4, 2, 3, 4, 5, 1, 3, 4, 5, 4, 3, 2, 6, 2, 1, 1, 6, 2, 2, 4, 3, 6, 2, 2, 3, 5, 3, 3, 4, 3, 3, 4, 4, 1, 2, 3, 4, 3, 6, 4, 1, 2, 5, 2, 5, 1, 2, 5, 6, 5, 1, 2, 3, 4, 1, 5, 3, 4, 2, 1, 4, 5, 1, 4, 5, 3, 4, 2, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 3, 4, 2, 4, 5, 3, 3, 3, 4, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 4, 5, 1, 5, 2, 2, 4, 6, 4, 3, 5, 4, 4, 1, 3, 4, 2, 3, 4, 4, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 5, 5, 3, 5, 3, 6, 3, 5, 3, 3, 1, 3, 4, 5, 1, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 4, 1, 2, 3, 1, 2, 3, 1, 1, 2, 1, 2, 4, 2, 1, 4, 5, 5, 3, 5, 1, 3, 4, 2, 1, 2, 1, 2, 4, 6, 6, 4, 6, 2, 4, 3, 4, 5, 3, 6, 5, 2, 4, 6, 1, 3, 5, 6, 6, 2, 5, 2, 6, 1, 4, 3, 5, 1, 2, 3, 1, 2, 1, 2, 1, 1, 3, 5, 3, 1, 3, 5, 1, 4, 6, 1, 3, 5, 6, 5, 5, 4, 2, 6, 6, 2, 4, 5, 6, 6, 1, 2, 3, 4, 5, 4, 5, 5, 2, 1, 3, 2, 3, 2, 2, 4, 6, 3, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 1, 2, 3, 1, 2, 3, 5, 1, 5, 2, 6, 5, 4, 2, 4, 2, 3, 5, 4, 1, 2, 3, 4, 5, 1, 5, 5, 2, 1, 2, 1, 1], \"Freq\": [0.994779320123507, 0.989258338599039, 0.9839245754203167, 0.9905247682440607, 0.9905297055330513, 0.6325666194967675, 0.1772937584056684, 0.18823781756651214, 0.9907102501837681, 0.9717490296241029, 0.9823985066387239, 0.9950262748409275, 0.9856372346910275, 0.003578247110658316, 0.8122620941194377, 0.1836833516804602, 0.9858924506236759, 0.001374676781339767, 0.8413021901799375, 0.15671315307273345, 0.30735976900491446, 0.6901096700299022, 0.3894663943176295, 0.5963704162988702, 0.2754123096486986, 0.4484925225930642, 0.2754123096486986, 0.7679068333614274, 0.2231524131135772, 0.8299261610092894, 0.16998487635130025, 0.9873984580374202, 0.9866841828330524, 0.9885993633633541, 0.1771756577225308, 0.5451558699154794, 0.2725779349577397, 0.9135749278622382, 0.08618631394926775, 0.993410238667749, 0.9927152346096092, 0.9877961186381546, 0.16899266738516694, 0.14136886598566847, 0.3363604052762457, 0.28111280247724885, 0.05362267330490873, 0.01787422443496958, 0.972531308736119, 0.5291928652988723, 0.28979609290176345, 0.18143755381675625, 0.9946454082384585, 0.9791954559910888, 0.7777238133609615, 0.22220680381741756, 0.13573324551253468, 0.48482644216517407, 0.1793131504262582, 0.17999408644053513, 0.01997412308545661, 0.3096560734740733, 0.5329968651435268, 0.15644644827087328, 0.027069891229500695, 0.9654927871855248, 0.9943090399097696, 0.2671388138237208, 0.6986707438466544, 0.0308237092873524, 0.9964038374086267, 0.9939469791993564, 0.9907101884249769, 0.983144273226983, 0.4832345316611145, 0.19853821843441138, 0.20228422255581538, 0.11238012364211966, 0.9802568816393489, 0.17620700958881913, 0.5959942971386529, 0.17879828914159587, 0.04923431150275828, 0.5649279079880881, 0.4337839293479962, 0.991811226648135, 0.9735620365333424, 0.9884800895688464, 0.9887210207159027, 0.9865906543853479, 0.437616883872293, 0.06659387363274023, 0.2092950314171836, 0.2822311787292324, 0.22333363162679243, 0.5376550391015373, 0.23574105560605868, 0.9863804487409162, 0.990822389448103, 0.2729691302946371, 0.30781625331097373, 0.4181654761960398, 0.9838260631458233, 0.9861368406544265, 0.9929697084400451, 0.990819541867343, 0.9928668008258327, 0.9766364917335776, 0.9804599241941059, 0.9933102501436127, 0.9828972065893097, 0.9055615080862273, 0.09138694118301377, 0.9864177390056755, 0.9907839492564847, 0.9795146660412352, 0.9820238889347523, 0.41014977963704163, 0.5866699379618444, 0.9866772180205354, 0.9919302691323002, 0.21856127628360011, 0.27593361130804517, 0.5054229514058253, 0.6412874144342224, 0.004885999348070266, 0.2540719660996539, 0.05374599282877293, 0.04519549396964997, 0.9688105130880285, 0.618260598769259, 0.37847892168004066, 0.17257845317353704, 0.20657117879862766, 0.619713536395883, 0.9926394939693902, 0.9909523205662436, 0.982203219455148, 0.013833848161340112, 0.7361026548486006, 0.15335471976012513, 0.111530705280091, 0.9956584486459648, 0.9927271592746417, 0.9864147294708209, 0.985939249761479, 0.9782394490237152, 0.9962536715061667, 0.6684112630533943, 0.3314662411043472, 0.9925434198251144, 0.3322455119643914, 0.17941257646077136, 0.13511317486551916, 0.35218024268225484, 0.3721093818113261, 0.35835938155963737, 0.2672656298921996, 0.0025781250471916357, 0.983389237610824, 0.992533331264269, 0.9963823943887027, 0.977897877424002, 0.9921105456188325, 0.9913467645646636, 0.9859307712411111, 0.9898786337596825, 0.9893693896476076, 0.8374509337668722, 0.16181255330410751, 0.9558361547986912, 0.04279863379695632, 0.9843701884857486, 0.8561053762311598, 0.13466826142962066, 0.9538264542627585, 0.9868750594625983, 0.7981992948288469, 0.20141477533064361, 0.9915452739389519, 0.9935960859930912, 0.9904402021715396, 0.9960820256156233, 0.20534502922825373, 0.08800501252639446, 0.24596272731735888, 0.4603339116765249, 0.261138813399196, 0.732873444055808, 0.9876742963425841, 0.9934501192780895, 0.4483536427260125, 0.5462699555052566, 0.9807200206425655, 0.9890194910540325, 0.2760215668419482, 0.7221934146138644, 0.9816321728029438, 0.9920249007749401, 0.9723250710900955, 0.38359913341298235, 0.08569767874119819, 0.15507199010312053, 0.37339702880093495, 0.15997278320825184, 0.8354134234208707, 0.9882833713082402, 0.9815213265579565, 0.9763973150500241, 0.008822219127529117, 0.9086885701354991, 0.07939997214776205, 0.16927596458776575, 0.07053165191156907, 0.7582152580493674, 0.9938324382693778, 0.9813597992777968, 0.9940334391938348, 0.11312385812344679, 0.4867753895008923, 0.39764750128241905, 0.31897635313264067, 0.012331560043787654, 0.29513533704798456, 0.19730496070060247, 0.17593025662470388, 0.41954467537634943, 0.34515732158621654, 0.15472569588347637, 0.0803383420933435, 0.9801854140050575, 0.9918615634583694, 0.28373378350970957, 0.6923104317636913, 0.01891558556731397, 0.996186085185544, 0.999032107911015, 0.6813348870661138, 0.31795628063085307, 0.3667783927115851, 0.058051256400394755, 0.1979020104558912, 0.04485778903666868, 0.32983668409315203, 0.12866969046722201, 0.24055637783002373, 0.6265654492316898, 0.007587787579416046, 0.3414504410737221, 0.35662601623255413, 0.2301628899089534, 0.06576082568827239, 0.9916966940459077, 0.958711661674667, 0.9723102756812774, 0.6781076895124822, 0.31841578464064385, 0.9800573887768156, 0.9943411321080243, 0.9796724844575554, 0.9816663763586679, 0.9885177608405757, 0.9916136169097853, 0.3323123573212303, 0.4997768523492519, 0.16746449502802158, 0.9979735177405702, 0.9983187976589403, 0.9792295167865663, 0.9928961879535475, 0.21061542585262258, 0.42965546873935007, 0.05054770220462942, 0.3117108302618814, 0.013338974303706997, 0.5450789954105724, 0.28678794752970044, 0.15521715553404505, 0.07487459573066639, 0.5615594679799979, 0.3618938793648876, 0.9837617901526753, 0.6510147070712763, 0.34685209802977834, 0.9905054622313546, 0.9854171718898672, 0.9918405462529299, 0.9887432223346081, 0.9895788645117976, 0.9749261886655685, 0.6835570710694724, 0.010089403263018043, 0.23205627504941498, 0.07314817365688081, 0.9900513433853714, 0.9848323475997628, 0.49685758439967653, 0.11254785060987148, 0.3870548033168751, 0.11691763195342461, 0.15883150001219948, 0.3948727569747737, 0.31104502085722396, 0.019853937501524935, 0.5784519142371707, 0.4199719377338363, 0.7179952596672837, 0.2752315162057921, 0.992986300508202, 0.2589440064780047, 0.27512800688287997, 0.46286241157943336, 0.9982711400663578, 0.042303276192200354, 0.9588742603565413, 0.40492847399754583, 0.5684089138102196, 0.025150836894257504, 0.9968304737935701, 0.38830834618006893, 0.4057997131251171, 0.20289985656255854, 0.9960166577766585, 0.8008030019511272, 0.19352739213818906, 0.6139118527445635, 0.22176551508834455, 0.16497190756571972, 0.9928357896676392, 0.9827796411867629, 0.9846662976313597, 0.9823245173801808, 0.46167004113386345, 0.532696201308304, 0.9822557880542214, 0.9893578632374731, 0.3536186160507294, 0.6440910506638287, 0.8546058986717854, 0.1344323885551123, 0.9933766756655229, 0.9946764667905215, 0.9966776328994961, 0.9893670111617461, 0.9897885440211505, 0.984700716793731, 0.23681997965529006, 0.7600269114518611, 0.9746805298676832, 0.9844816484789584, 0.9897353265726007, 0.9785986380105787, 0.9879940337585009, 0.9835613253012297, 0.9852972641695346, 0.9750558964976709, 0.9837965330684708, 0.9826257417723152, 0.9973246269251813, 0.9752371960312666, 0.5468798358697324, 0.45251625634711196, 0.8980035726390454, 0.038605761066725315, 0.06378343132763313, 0.97264314977765, 0.02202210905156943, 0.9877109116508347, 0.9922013565875535, 0.9876190114640384, 0.2690410164557333, 0.6545740194180728, 0.07627451497456357, 0.9955412357578672, 0.9808419824379188, 0.9894917351073914, 0.9923601638639349, 0.9851987004527964, 0.9943295104095433, 0.9843559592569632, 0.17122981672780882, 0.7688218771078615, 0.0017122981672780882, 0.05650583952017691, 0.9727801844980655, 0.9879990541507863, 0.9902012119249909, 0.9863368636002364, 0.994030390698585, 0.9767843993759806, 0.19220832162821488, 0.7988658367672681, 0.9767919740357195, 0.9881413588317476, 0.9815494471065381, 0.12933982536700764, 0.3196890023222264, 0.002440374063528446, 0.36117536140221, 0.1854684288281619, 0.9921147328424746, 0.9753085683548967, 0.9770008018750866, 0.995281736892942, 0.6237478750549177, 0.372928623710083, 0.9802582144539017, 0.9768920950689244, 0.9894204414385013, 0.8809574597664557, 0.1157462355897533, 0.992415947010636, 0.9889998380285526, 0.3577448389820453, 0.23458677966035757, 0.3274440466092491, 0.07917303813537067, 0.16539994446712242, 0.36692171588683475, 0.1958183250587771, 0.2566550862420865, 0.015209190295827348, 0.9826437614795133, 0.4353175502843304, 0.3805919153914431, 0.18407713554880256, 0.013782765732728665, 0.13782765732728666, 0.6684641380373403, 0.17917595452547264, 0.3760250741875741, 0.6248651968117039, 0.012158181281322964, 0.98481268378716, 0.9708488562860507, 0.9918535754754781, 0.7593529121982064, 0.24013724573789436, 0.48131518845368515, 0.21671783354459123, 0.29987700223030644, 0.9973185430321153, 0.30869899457627653, 0.005291982764164741, 0.3766127733830574, 0.3078169974489158, 0.0008819971273607901, 0.1389524793734959, 0.8510839361626624, 0.9908734541530585, 0.982363282245007, 0.9970514921266941, 0.9862810388368982, 0.9860466772078417, 0.9831818047268016], \"Term\": [\"101\", \"64gb\", \"ablet\", \"access\", \"actually\", \"adapter\", \"adapter\", \"adapter\", \"added\", \"addition\", \"additional\", \"advertised\", \"ago\", \"alaxy\", \"alaxy\", \"alaxy\", \"amazon\", \"amsung\", \"amsung\", \"amsung\", \"andisk\", \"andisk\", \"android\", \"android\", \"anisk\", \"anisk\", \"anisk\", \"apps\", \"apps\", \"ard\", \"ard\", \"ave\", \"awesome\", \"backup\", \"bad\", \"bad\", \"bad\", \"best\", \"best\", \"better\", \"big\", \"black\", \"bought\", \"bought\", \"bought\", \"bought\", \"bought\", \"bought\", \"bucks\", \"buy\", \"buy\", \"buy\", \"buying\", \"cam\", \"camera\", \"camera\", \"card\", \"card\", \"card\", \"card\", \"card\", \"cards\", \"cards\", \"cards\", \"cell\", \"cell\", \"cheaper\", \"chip\", \"chip\", \"chip\", \"class\", \"come\", \"complaints\", \"completely\", \"computer\", \"computer\", \"computer\", \"computer\", \"customer\", \"data\", \"data\", \"data\", \"data\", \"day\", \"day\", \"days\", \"decent\", \"defective\", \"delete\", \"described\", \"device\", \"device\", \"device\", \"device\", \"devices\", \"devices\", \"devices\", \"died\", \"digital\", \"dont\", \"dont\", \"dont\", \"download\", \"drives\", \"ead\", \"emory\", \"ero\", \"error\", \"errors\", \"ery\", \"especially\", \"excellent\", \"excellent\", \"expand\", \"expect\", \"expensive\", \"external\", \"extra\", \"extra\", \"fact\", \"failed\", \"far\", \"far\", \"far\", \"fast\", \"fast\", \"fast\", \"fast\", \"fast\", \"feel\", \"files\", \"files\", \"fine\", \"fine\", \"fine\", \"fit\", \"fits\", \"flash\", \"flash\", \"format\", \"format\", \"format\", \"free\", \"galaxy\", \"genuine\", \"gigs\", \"goes\", \"going\", \"good\", \"good\", \"gopro\", \"got\", \"got\", \"got\", \"got\", \"great\", \"great\", \"great\", \"great\", \"half\", \"hard\", \"hat\", \"hats\", \"hey\", \"high\", \"highly\", \"hope\", \"hours\", \"icro\", \"icro\", \"immediately\", \"immediately\", \"included\", \"indows\", \"indows\", \"insert\", \"install\", \"installed\", \"installed\", \"instead\", \"internal\", \"isnt\", \"issue\", \"issues\", \"issues\", \"issues\", \"issues\", \"item\", \"item\", \"items\", \"job\", \"know\", \"know\", \"lack\", \"lag\", \"lass\", \"lass\", \"later\", \"left\", \"lenty\", \"like\", \"like\", \"like\", \"like\", \"load\", \"load\", \"loaded\", \"look\", \"lose\", \"lost\", \"lost\", \"lost\", \"lot\", \"lot\", \"lot\", \"lots\", \"lso\", \"ltra\", \"mazon\", \"mazon\", \"mazon\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"micro\", \"micro\", \"micro\", \"micro\", \"microsd\", \"mobile\", \"months\", \"months\", \"months\", \"movies\", \"music\", \"ndroid\", \"ndroid\", \"need\", \"need\", \"need\", \"need\", \"need\", \"needed\", \"needed\", \"needed\", \"new\", \"new\", \"new\", \"new\", \"new\", \"nice\", \"nly\", \"noticed\", \"old\", \"old\", \"ony\", \"ood\", \"ook\", \"option\", \"order\", \"orked\", \"orks\", \"orks\", \"orks\", \"oro\", \"ote\", \"ould\", \"past\", \"perfectly\", \"perfectly\", \"perfectly\", \"perfectly\", \"phone\", \"phone\", \"phone\", \"phone\", \"photos\", \"photos\", \"photos\", \"pics\", \"pictures\", \"pictures\", \"play\", \"player\", \"plenty\", \"plug\", \"plus\", \"popped\", \"price\", \"price\", \"price\", \"price\", \"priced\", \"pro\", \"problem\", \"problem\", \"problem\", \"problems\", \"problems\", \"problems\", \"problems\", \"problems\", \"product\", \"product\", \"products\", \"products\", \"purchase\", \"purchased\", \"purchased\", \"purchased\", \"quality\", \"rating\", \"rating\", \"read\", \"read\", \"read\", \"reader\", \"really\", \"really\", \"really\", \"reat\", \"recognized\", \"recognized\", \"recommend\", \"recommend\", \"recommend\", \"recommended\", \"record\", \"reformatted\", \"regular\", \"reliable\", \"reliable\", \"replace\", \"replacement\", \"return\", \"return\", \"review\", \"review\", \"room\", \"run\", \"running\", \"said\", \"samsung\", \"save\", \"say\", \"say\", \"saying\", \"sec\", \"second\", \"seconds\", \"send\", \"sent\", \"service\", \"shooting\", \"sing\", \"single\", \"size\", \"soon\", \"space\", \"space\", \"speed\", \"speed\", \"speed\", \"speeds\", \"speeds\", \"standard\", \"star\", \"start\", \"storage\", \"storage\", \"storage\", \"store\", \"stores\", \"storing\", \"stuff\", \"super\", \"sure\", \"sus\", \"tablet\", \"tablet\", \"tablet\", \"tablet\", \"taken\", \"taking\", \"tell\", \"test\", \"tested\", \"tests\", \"think\", \"think\", \"thinking\", \"thumb\", \"till\", \"time\", \"time\", \"time\", \"time\", \"time\", \"tiny\", \"told\", \"tons\", \"took\", \"transfer\", \"transfer\", \"transferred\", \"transferring\", \"transfers\", \"tried\", \"tried\", \"trust\", \"urface\", \"use\", \"use\", \"use\", \"use\", \"using\", \"using\", \"using\", \"using\", \"using\", \"value\", \"video\", \"video\", \"video\", \"videos\", \"videos\", \"videos\", \"videos\", \"want\", \"want\", \"warranty\", \"warranty\", \"wifes\", \"wish\", \"work\", \"work\", \"worked\", \"worked\", \"worked\", \"working\", \"works\", \"works\", \"works\", \"works\", \"works\", \"worry\", \"worry\", \"worth\", \"wouldnt\", \"write\", \"writing\", \"wrong\", \"youre\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 6, 3, 1, 2, 4]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el823644584111364998494441\", ldavis_el823644584111364998494441_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el823644584111364998494441\", ldavis_el823644584111364998494441_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el823644584111364998494441\", ldavis_el823644584111364998494441_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panel = pyLDAvis.sklearn.prepare(lda_model_dict['lda_model_6'], data_vectorized, vectorizer, mds='tsne')\n",
    "pyLDAvis.display(panel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
